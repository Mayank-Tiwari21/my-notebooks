{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f51d09-0962-430e-a6fe-ff6165f5fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b77f4b-0220-4fcc-8693-f368d7390b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c126d4-a37d-4082-aabf-3c1a26efa45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/27 11:36:53 WARN Utils: Your hostname, TTNPL-8203 resolves to a loopback address: 127.0.1.1; using 10.1.243.232 instead (on interface wlp0s20f3)\n",
      "25/03/27 11:36:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/27 11:36:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/27 11:36:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7ca08b5007f0>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"pivot example\").getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea862e-010f-4413-8eca-c912d85d1431",
   "metadata": {},
   "source": [
    "# **Improved Solution for Customer Balance Calculation**\n",
    "\n",
    "## **Problem Statement**\n",
    "We have two datasets:\n",
    "1. **Transactions**: customer_id, transaction_type (credit/debit), transaction_amount\n",
    "2. **Current Amounts**: customer_id, current_amount\n",
    "\n",
    "**Goal**: Calculate each customer's final balance after applying all transactions.\n",
    "\n",
    "### **Input Tables**\n",
    "\n",
    "#### **Transactions Table**\n",
    "+-----------+-----------------+-------------------+\n",
    "|customer_id|transaction_type |transaction_amount |\n",
    "+-----------+-----------------+-------------------+\n",
    "|1          |credit           |30                 |\n",
    "|1          |debit            |90                 |\n",
    "|2          |credit           |50                 |\n",
    "|2          |debit            |90                 |\n",
    "|3          |debit            |57                 |\n",
    "+-----------+-----------------+-------------------+\n",
    "\n",
    "#### **Current Amounts Table**\n",
    "+-----------+--------------+\n",
    "|customer_id|current_amount|\n",
    "+-----------+--------------+\n",
    "|1          |1000          |\n",
    "|2          |2000          |\n",
    "|3          |3000          |\n",
    "|4          |4000          |\n",
    "+-----------+--------------+\n",
    "\n",
    "### **Expected Output**\n",
    "+-----------+--------------+\n",
    "|customer_id|final_balance |\n",
    "+-----------+--------------+\n",
    "|1          |940           |\n",
    "|2          |1960          |\n",
    "|3          |2943          |\n",
    "|4          |4000          |\n",
    "+-----------+--------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587cad95-5c64-4810-a561-da2e7302f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/customers_amt.csv\",header = True,inferSchema = True)\n",
    "df2 = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/transactions.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f755cf-87a4-44a3-9c2e-3d4fdb6aaba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|customer_id|current_amount|\n",
      "+-----------+--------------+\n",
      "|          1|          1000|\n",
      "|          2|          1500|\n",
      "|          3|           800|\n",
      "|          4|          2000|\n",
      "|          5|          1300|\n",
      "+-----------+--------------+\n",
      "\n",
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- current_amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12dc1c5a-f898-4a1d-b019-d3cef2e56bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------------+\n",
      "|customer_id|transaction_type|transaction_amount|\n",
      "+-----------+----------------+------------------+\n",
      "|          1|          credit|               500|\n",
      "|          1|           debit|               200|\n",
      "|          2|          credit|              1000|\n",
      "|          2|           debit|               300|\n",
      "|          3|          credit|               700|\n",
      "|          3|           debit|               400|\n",
      "|          4|          credit|              1200|\n",
      "|          4|           debit|               500|\n",
      "|          5|          credit|               900|\n",
      "|          5|           debit|               300|\n",
      "+-----------+----------------+------------------+\n",
      "\n",
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17296267-d10a-4f04-91b1-48572b52dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumn(\"new_tr_amt\",when(col(\"transaction_type\") == \"debit\",col(\"transaction_amount\")*-1).otherwise(col(\"transaction_amount\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdec5765-3b73-49fc-a1cc-c059bdfd3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.groupBy(\"customer_id\").agg(\n",
    "    sum(\"new_tr_amt\").alias(\"new_tr_amt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545ae2b4-e45f-4c0e-85f1-08c7cae6bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|customer_id|Final_Balance|\n",
      "+-----------+-------------+\n",
      "|          1|         1300|\n",
      "|          2|         2200|\n",
      "|          3|         1100|\n",
      "|          4|         2700|\n",
      "|          5|         1900|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df4,\"customer_id\",\"full\").withColumn(\"Final_Balance\",col(\"current_amount\")+col(\"new_tr_amt\")).select(\"customer_id\",\"Final_Balance\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57e0dc-da49-4546-b987-abf077069162",
   "metadata": {},
   "source": [
    "# **Improved Solution for Quarterly Sales Percentage Difference Calculation**\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "We have a sales dataset with the following structure:\n",
    "\n",
    "### **Sales Data Table**\n",
    "+----------+------+\n",
    "|   date   |sales |\n",
    "+----------+------+\n",
    "|2020-01-15| 1000|\n",
    "|2020-02-20| 1500|\n",
    "|2020-03-10| 2000|  # Q1\n",
    "|2020-04-05| 1200|\n",
    "|2020-05-12| 1800|\n",
    "|2020-06-08| 2200|  # Q2\n",
    "|2021-01-10| 1100|\n",
    "|2021-02-15| 1600|\n",
    "|2021-03-20| 2100|  # Q1\n",
    "|2021-04-25| 1300|\n",
    "|2021-05-30| 1900|\n",
    "|2021-06-05| 2300|  # Q2\n",
    "+----------+------+\n",
    "\n",
    "**Goal**: Calculate the percentage difference between total sales in Q1 and Q2 for each year.\n",
    "\n",
    "### **Expected Output**\n",
    "+----+-----------+-----------+------------------+\n",
    "|year|q1_sales   |q2_sales   |pct_difference    |\n",
    "+----+-----------+-----------+------------------+\n",
    "|2020|4500       |5200       |15.56%            |\n",
    "|2021|4800       |5500       |14.58%            |\n",
    "+----+-----------+-----------+------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd8d586-51cb-41b6-80a7-fd4412a77d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/question2.csv\",header =True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6db0661-529a-480d-8434-f89b829385ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- sales: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3ef902-fbd6-4775-809d-f52161e0d92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|sales|\n",
      "+----------+-----+\n",
      "|2020-01-15| 1000|\n",
      "|2020-02-20| 1500|\n",
      "|2020-03-10| 2000|\n",
      "|2020-04-05| 1200|\n",
      "|2020-05-12| 1800|\n",
      "|2020-06-08| 2200|\n",
      "|2021-01-10| 1100|\n",
      "|2021-02-15| 1600|\n",
      "|2021-03-20| 2100|\n",
      "|2021-04-25| 1300|\n",
      "|2021-05-30| 1900|\n",
      "|2021-06-05| 2300|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e521492-4b3d-4de9-b6c8-cf2ecb96bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"quarter\",quarter(col(\"date\"))).withColumn(\"year\",year(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "705b6f20-d74c-4a34-a4a4-6c9e27a84de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df1.groupBy(\"quarter\",\"year\").agg(\n",
    "    sum(\"sales\").alias(\"sales\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8d16589-e06f-4e20-b777-15f926f443df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+\n",
      "|quarter|year|sales|\n",
      "+-------+----+-----+\n",
      "|      1|2021| 4800|\n",
      "|      2|2021| 5500|\n",
      "|      1|2020| 4500|\n",
      "|      2|2020| 5200|\n",
      "+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "530dd960-af61-4b46-9cdc-ae102f7507b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|year|  q1|  q2|\n",
      "+----+----+----+\n",
      "|2020|4500|5200|\n",
      "|2021|4800|5500|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"year\").pivot(\"quarter\",[1,2]).agg(first(col(\"sales\"))\n",
    "                                              ).withColumnRenamed(\"1\",\"q1\").withColumnRenamed(\"2\",\"q2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6eaee9a-c3fe-4119-a887-b884b8246684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|sales|\n",
      "+----+-----+\n",
      "|2020| 9700|\n",
      "|2021|10300|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.filter(col(\"quarter\").isin([1,2])).groupBy(\"year\").agg(\n",
    "    sum(\"sales\").alias(\"sales\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8e253-e749-4190-8227-11101730bf63",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "You are given a dataset containing customer journey details with multiple records for each customer. Each record represents a travel leg with a start location and an end location. Your task is to determine the overall start location and end location for each customer’s complete journey.\n",
    "For each customer:\n",
    "\n",
    "\n",
    "#### Start Location = The location from which their journey began.\n",
    "\n",
    "\n",
    "#### End Location = The final destination of their journey.\n",
    "\n",
    "\n",
    "#### Example Input Table (customer_journey)\n",
    "\n",
    "\n",
    "| customer_id | start_location | end_location |\n",
    "|------------|---------------|-------------|\n",
    "| C1         | London        | Paris       |\n",
    "| C1         | Paris        | Berlin      |\n",
    "| C1         | Berlin       | New Delhi   |\n",
    "| C2         | Mumbai       | Pune        |\n",
    "| C2         | Pune         | Hyderabad   |\n",
    "| C3         | Kochi        | Lucknow     |\n",
    "| C3         | Lucknow      | Agra        |\n",
    "\n",
    "### Customer Journey Summary\n",
    "\n",
    "| customer_id | start_location | end_location |\n",
    "|------------|---------------|-------------|\n",
    "| C1         | London        | New Delhi   |\n",
    "| C2         | Mumbai       | Hyderabad   |\n",
    "| C3         | Kochi        | Agra        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "298d350a-8ad5-4898-a525-ee1e3ab8a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/travel.csv\",header = True,inferSchema =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "204e3361-947d-4763-914d-b50850bb79c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- start_location: string (nullable = true)\n",
      " |-- end_location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf8e3b70-6fae-4d2f-b4a7-9f81cf6be8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+------------+\n",
      "|customer_id|start_location|end_location|\n",
      "+-----------+--------------+------------+\n",
      "|         C1|        London|       Paris|\n",
      "|         C1|         Paris|      Berlin|\n",
      "|         C1|        Berlin|   New Delhi|\n",
      "|         C2|        Mumbai|        Pune|\n",
      "|         C2|          Pune|   Hyderabad|\n",
      "|         C3|         Kochi|     Lucknow|\n",
      "|         C3|       Lucknow|        Agra|\n",
      "+-----------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd4d3ee8-06f6-4672-9af1-5955cc7ce9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupBy(\"customer_id\").agg(\n",
    "    collect_list(\"start_location\").alias(\"start_loc\"),\n",
    "    collect_list(\"end_location\").alias(\"end_loc\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd3e5ac0-e380-4116-a3e0-a174aa823581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|customer_id|           start_loc|             end_loc|\n",
      "+-----------+--------------------+--------------------+\n",
      "|         C3|    [Kochi, Lucknow]|     [Lucknow, Agra]|\n",
      "|         C1|[London, Paris, B...|[Paris, Berlin, N...|\n",
      "|         C2|      [Mumbai, Pune]|   [Pune, Hyderabad]|\n",
      "+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5da689c5-4438-41ea-9c5d-3b54841ae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(StringType()))\n",
    "def destination_router(arr1, arr2):\n",
    "    if not arr1 or not arr2:  # Handle empty inputs\n",
    "        return []\n",
    "    for val in arr1:\n",
    "        if val not in arr2:\n",
    "            source = val\n",
    "    for val in arr2:\n",
    "        if val not in arr1:\n",
    "            destination = val\n",
    "    return [source, destination]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd934267-70db-4e37-9004-5cb0dd6be2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'destination_router(array(1, 2, 3, 4), array(2, 3, 4, 5))'>\n"
     ]
    }
   ],
   "source": [
    "print(destination_router(lit([1,2,3,4]),lit([2,3,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5fba3223-d5c7-4bc3-aecf-f5a67fe7baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.withColumn(\"source-destination\",destination_router(col(\"start_loc\"),col(\"end_loc\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21539b93-5111-42e3-a341-2dd1d05a61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumn(\"source\",col(\"source-destination\").getItem(0)).withColumn(\"destination\",col(\"source-destination\").getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3179e876-f6f7-4d74-87cd-2e0965f6a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+-------------------+------+-----------+\n",
      "|customer_id|           start_loc|             end_loc| source-destination|source|destination|\n",
      "+-----------+--------------------+--------------------+-------------------+------+-----------+\n",
      "|         C3|    [Kochi, Lucknow]|     [Lucknow, Agra]|      [Kochi, Agra]| Kochi|       Agra|\n",
      "|         C1|[London, Paris, B...|[Paris, Berlin, N...|[London, New Delhi]|London|  New Delhi|\n",
      "|         C2|      [Mumbai, Pune]|   [Pune, Hyderabad]|[Mumbai, Hyderabad]|Mumbai|  Hyderabad|\n",
      "+-----------+--------------------+--------------------+-------------------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "22057c78-1499-46ab-b89e-c837613ddda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(\"start_loc\").drop(\"end_loc\").drop(\"source-destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bd55ea70-f343-4d2c-9c16-c32fc6137cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----------+\n",
      "|customer_id|source|destination|\n",
      "+-----------+------+-----------+\n",
      "|         C3| Kochi|       Agra|\n",
      "|         C1|London|  New Delhi|\n",
      "|         C2|Mumbai|  Hyderabad|\n",
      "+-----------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5025eb-ad54-4e1e-81a4-48dba9ee494a",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "Given an employee dataset with two columns (name and age), we need to extract the third quarter (25%) of the dataset. The dataset should be divided into four equal parts, and only the third quarter should be selected.\n",
    "\n",
    "Input Table: Employee Data\n",
    "\n",
    "\n",
    "\n",
    "+---------+-----+\n",
    "|  Name   | Age |\n",
    "+---------+-----+\n",
    "| Alice   |  25 |\n",
    "| Bob     |  30 |\n",
    "| Charlie |  35 |\n",
    "| David   |  40 |\n",
    "| Eve     |  45 |\n",
    "| Frank   |  50 |\n",
    "| Grace   |  55 |\n",
    "| Helen   |  60 |\n",
    "+---------+-----+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8139802e-1fda-487f-a2bc-de4532cb14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/age-name.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28109d9f-ac7d-4362-bdd2-6c04513554ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d839b-b65b-43ea-b947-9d73e99ece00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad33d6-9ee9-4856-998f-897bc62df96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f5a09e-be90-4033-bf78-b0653c4c8f93",
   "metadata": {},
   "source": [
    "## Movie-Watch-List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ee1944a-482a-48df-b5c8-819685dda3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_df = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/movie-watch-list/customer.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97b05303-215a-407d-929a-d62bd5164efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_df = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/movie-watch-list/movie.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "32e97973-6fa4-4fc0-9d39-95cc7f238bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieWatchList = spark.read.csv(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/movie-watch-list/movieWatchList.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "54f87806-16f7-4433-8801-f6a39f180f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- subscription: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cus_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d32bc5af-d7f0-47bc-b624-474537f310e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- actor: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mov_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "91894dd1-2086-4049-9115-95a793ff48d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- cus_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieWatchList.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a356022b-668d-4d10-ad8e-2e51e0103b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchList = movieWatchList.join(cus_df.select(\"customer_id\",\"name\"),cus_df[\"customer_id\"]==movieWatchList[\"cus_id\"],\"inner\").select(\"movie_id\",\"cus_id\",\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "447d8de6-9db3-4ed1-9060-81ac8f1aeed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- cus_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchList.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f308dc5a-9cc9-4d24-9cc6-93ec6654ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchList2 = watchList.groupBy(\"movie_id\").agg(\n",
    "    collect_list(\"cus_id\").alias(\"customer_id_list\"),\n",
    "    collect_list(\"name\").alias(\"customer_name_list\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f5aea70-d844-4381-b6ce-53ebcb37d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------------+--------------------+------------------+\n",
      "|movie_id|         director|            actor|         description|customer_name_list|\n",
      "+--------+-----------------+-----------------+--------------------+------------------+\n",
      "|     101|Christopher Nolan|Leonardo DiCaprio|A mind-bending th...|  [Alice, Charlie]|\n",
      "|     103|Quentin Tarantino|Samuel L. Jackson|A stylish crime m...|         [Charlie]|\n",
      "|     102| Steven Spielberg|        Tom Hanks|A gripping war dr...| [Bob, David, Eve]|\n",
      "|     105|    James Cameron|     Kate Winslet|A romantic drama ...|             [Eve]|\n",
      "|     104|  Martin Scorsese|   Robert De Niro|A classic gangste...|           [David]|\n",
      "+--------+-----------------+-----------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchList2.join(mov_df,mov_df.movie_id == watchList2.movie_id,\"left\").select(mov_df[\"movie_id\"],\"director\",\"actor\",\"description\",\"customer_name_list\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "87e3acce-d61e-4ff1-bbcb-678e2213e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_watchList = watchList2.join(mov_df,mov_df.movie_id == watchList2.movie_id,\"left\").select(mov_df[\"movie_id\"],\"director\",\"actor\",\"description\",\"customer_name_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "94fe76b8-9b78-482f-aa71-c83f364c9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_watchList_with_no = final_watchList.withColumn(\"no_of_watcher\",size(\"customer_name_list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "53d9c8f1-bb23-47aa-88e4-d97cb632b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------------+--------------------+------------------+-------------+\n",
      "|movie_id|         director|            actor|         description|customer_name_list|no_of_watcher|\n",
      "+--------+-----------------+-----------------+--------------------+------------------+-------------+\n",
      "|     101|Christopher Nolan|Leonardo DiCaprio|A mind-bending th...|  [Alice, Charlie]|            2|\n",
      "|     103|Quentin Tarantino|Samuel L. Jackson|A stylish crime m...|         [Charlie]|            1|\n",
      "|     102| Steven Spielberg|        Tom Hanks|A gripping war dr...| [Bob, David, Eve]|            3|\n",
      "|     105|    James Cameron|     Kate Winslet|A romantic drama ...|             [Eve]|            1|\n",
      "|     104|  Martin Scorsese|   Robert De Niro|A classic gangste...|           [David]|            1|\n",
      "+--------+-----------------+-----------------+--------------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_watchList_with_no.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69e3a0-8854-48a5-92ef-f5f949e10fb7",
   "metadata": {},
   "source": [
    "## Data Seggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9c01392f-86c7-4c9e-bd98-575276b3353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"file:///home/hdoop/notebooks/data/spark_practice/examples_27Mar2025/data-seggregation-folder/RawData.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b8eb70f3-961b-430a-a966-fd4701a35347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|                    |\n",
      "|customer_id|name|...|\n",
      "|1|Alice|active|10...|\n",
      "|2|Bob|inactive|10...|\n",
      "|3|Charlie||103|3|...|\n",
      "|4|David|active|10...|\n",
      "|5|Eve|inactive|10...|\n",
      "|6||active|106|6|2...|\n",
      "|7|Grace|inactive|...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "889f6ee0-ab1f-4cb7-ae31-9556acc10d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"value\",split(\"value\",'[|]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "54b1d9c0-26f0-4dc2-aa2e-c8eab6a74c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|               value|no_of_columns|\n",
      "+--------------------+-------------+\n",
      "|                  []|            1|\n",
      "|[customer_id, nam...|            9|\n",
      "|[1, Alice, active...|            9|\n",
      "|[2, Bob, inactive...|            9|\n",
      "|[3, Charlie, , 10...|            9|\n",
      "|[4, David, active...|            9|\n",
      "|[5, Eve, inactive...|            9|\n",
      "|[6, , active, 106...|            9|\n",
      "|[7, Grace, inacti...|            9|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.withColumn(\"no_of_columns\",size(\"value\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "901c3710-5aa3-4088-9bba-762b495d1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.filter(df1[\"value\"].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9e1002a6-adf1-41d2-99b6-fd6e3ad3890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[]                                                                                                                               |\n",
      "|[customer_id, name, subscription, movie_id, cus_id, date, director, actor, description]                                          |\n",
      "|[1, Alice, active, 101, 1, 2024-03-01, Christopher Nolan, Leonardo DiCaprio, A mind-bending thriller about dreams within dreams.]|\n",
      "|[2, Bob, inactive, 102, 2, 2024-03-05, Steven Spielberg, Tom Hanks, A gripping war drama set during World War II.]               |\n",
      "|[3, Charlie, , 103, 3, 2024-03-10, Quentin Tarantino, Samuel L. Jackson, A stylish crime movie with sharp dialogues.]            |\n",
      "|[4, David, active, 104, , 2024-03-15, Martin Scorsese, Robert De Niro, A classic gangster film about power and betrayal.]        |\n",
      "|[5, Eve, inactive, 105, 5,  , James Cameron, Kate Winslet, A romantic drama set on the ill-fated Titanic.]                       |\n",
      "|[6, , active, 106, 6, 2024-03-25, Ridley Scott, Russell Crowe, An epic historical drama set in ancient Rome.]                    |\n",
      "|[7, Grace, inactive, , , 2024-03-30, Stanley Kubrick, Jack Nicholson, A psychological horror film set in a haunted hotel.]       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411958d-af28-43de-abee-185f6245036e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
