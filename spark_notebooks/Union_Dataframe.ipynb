{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3c7d7d-a4fa-4be8-90cb-826789d7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee215446-9b59-49d6-8a3f-c648ea7db5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/22 16:44:31 WARN Utils: Your hostname, TTNPL-8203 resolves to a loopback address: 127.0.1.1; using 192.168.163.68 instead (on interface wlp0s20f3)\n",
      "25/03/22 16:44:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/22 16:44:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .appName(\"Union on Dataframes\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1066d8f-21ad-4f26-b226-f60121d0ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7ac2b51d0ac0>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cdc618e-6c5a-4e5e-8ea8-77dd0929a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24c1836-c394-4b1f-abd3-20e63b2063a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- bonus: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data= [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "       (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "       (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "       (\"Maria\",\"Finance\",\"CA\",90000,24,23000)\n",
    "      ]\n",
    "schema = StructType([\n",
    "    StructField(\"employee_name\",StringType(),True),\n",
    "    StructField(\"department\",StringType(),True),\n",
    "    StructField(\"state\",StringType(),True),\n",
    "    StructField(\"salary\",IntegerType(),True),\n",
    "    StructField(\"age\",IntegerType(),True),\n",
    "    StructField(\"bonus\",IntegerType(),True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data = data ,schema =schema)\n",
    "df.printSchema()\n",
    "df.show(truncate =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e6b005-042a-40fc-8618-d2e515e8848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- bonus: integer (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData2 = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "df2 = spark.createDataFrame(data = simpleData2 , schema =schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ac65a-7143-4eda-a785-93a074917b75",
   "metadata": {},
   "source": [
    "#### union - returns all the rows duplicate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72933d4a-bc67-4841-8c77-98a839a4c325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionDF = df.union(df2)\n",
    "unionDF.show(truncate =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e425bb-c57b-45a9-b9d0-46f15619d0f4",
   "metadata": {},
   "source": [
    "#### unionAll - depricated same as union but usually it keeps all the records and the union eliminates the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236934ea-d519-4216-80c4-bff2a481dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unionAllDF = df.unionAll(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f536d49-ff4c-4dd2-bc38-c49461184505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionAllDF.show(truncate =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7802ed-9fb3-4134-bf19-d6838c827276",
   "metadata": {},
   "source": [
    "#### to eliminate the duplicates use the distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f5088e-2533-4bd5-9785-d5cb912356d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================================================>   (15 + 1) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "unionDF_distinct = df.union(df2).distinct()\n",
    "unionDF_distinct.show(truncate =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205352b-13dc-41ea-b145-a16a07924db7",
   "metadata": {},
   "source": [
    "#### unionByName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7454fe26-b5fd-4437-8d80-f57a77aa920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(data = [(1,\"a\",2.0),(2,\"b\",3.0),(3,\"h\",4.0)],schema = [\"id\",\"name\",\"score1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79b0732-0abd-4fde-a66d-46c40f258a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- score1: double (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3377bad-8a6f-4334-8848-8cdc3d7758b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(data = [(7,\"b\",4),(8,\"l\",5)],schema = [\"id\",\"name\",\"score0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528bf187-3628-474a-a66b-c67ef767068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+\n",
      "| id|name|score1|score0|\n",
      "+---+----+------+------+\n",
      "|  1|   a|   2.0|  NULL|\n",
      "|  2|   b|   3.0|  NULL|\n",
      "|  3|   h|   4.0|  NULL|\n",
      "|  7|   b|  NULL|     4|\n",
      "|  8|   l|  NULL|     5|\n",
      "+---+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionByName(df2,allowMissingColumns = True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47e9971d-c252-4c37-8093-f59f9f0056db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|score1|\n",
      "+---+----+------+\n",
      "|  1|   a|   2.0|\n",
      "|  2|   b|   3.0|\n",
      "|  3|   h|   4.0|\n",
      "|  7|   b|   4.0|\n",
      "|  8|   l|   5.0|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43bec0dd-b89e-4ba1-897b-10fa6a9b6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+\n",
      "| id|score0|name|\n",
      "+---+------+----+\n",
      "|  7|     4|   b|\n",
      "|  8|     5|   l|\n",
      "+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data = [(7,4,\"b\"),(8,5,\"l\")],schema = [\"id\",\"score0\",\"name\"])\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8a7b0eb-5141-49c6-b272-b4c490338b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|score1|\n",
      "+---+----+------+\n",
      "|  1|   a|   2.0|\n",
      "|  2|   b|   3.0|\n",
      "|  3|   h|   4.0|\n",
      "|  7|   b|   4.0|\n",
      "|  8|   l|   5.0|\n",
      "+---+----+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- score1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df3.select(df3.id,df3.name,df3.score0)).show()\n",
    "df1.union(df3).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03a1769e-d853-4a9c-b878-3305508891d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+\n",
      "| id|name|score1|score0|\n",
      "+---+----+------+------+\n",
      "|  1|   a|   2.0|  NULL|\n",
      "|  2|   b|   3.0|  NULL|\n",
      "|  3|   h|   4.0|  NULL|\n",
      "|  7|   b|  NULL|     4|\n",
      "|  8|   l|  NULL|     5|\n",
      "+---+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionByName(df3,allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5135ef98-5e30-4653-beea-5a5a6fff3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85533e8-b7fc-4830-853d-08ffffcb2040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
